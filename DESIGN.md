# Prompt Engineer - Design Document

## Core Concepts

### 1. Workspace-Centric Architecture

Prompt Engineer is a **workbench tool** that points to prompts in your application's source code. It does NOT store prompts - your app's git repository is the source of truth.

```
Your App Repo/
â”œâ”€â”€ src/main/resources/prompts/     # Production prompts
â”‚   â”œâ”€â”€ system-evaluator.st
â”‚   â”œâ”€â”€ user-evaluator.st
â”‚   â”œâ”€â”€ system-optimizer.st
â”‚   â””â”€â”€ user-optimizer.st
â”œâ”€â”€ src/test/resources/prompts/vars/ # Dev/test variable configs
â”‚   â”œâ”€â”€ evaluator.yaml
â”‚   â”œâ”€â”€ optimizer.yaml
â”‚   â””â”€â”€ evaluator-optimizer-chain.yaml
â””â”€â”€ .prompt-engineer/
    â””â”€â”€ workspace.yaml               # Workspace configuration
```

---

## Workspace Configuration

### Basic Structure

```yaml
# .prompt-engineer/workspace.yaml
name: "MyApp Prompts Workspace"
version: "1.0"

# Project layout
layout:
  prompt_dir: "src/main/resources/prompts"
  vars_dir: "src/test/resources/prompts/vars"
  chains_dir: "src/test/resources/prompts/chains"  # Optional

  # File extensions
  prompt_extension: ".st"      # StringTemplate files
  vars_extension: ".yaml"       # Variable config files

# Template syntax configuration
template:
  # Variable delimiter configuration
  variable_delimiters:
    start: "{"          # Start delimiter (default: "{")
    end: "}"            # End delimiter (default: "}")

  # Examples of other delimiter configs:
  # start: "$", end: "$"     # For $var$
  # start: "<", end: ">"     # For <var>
  # start: "[[", end: "]]"   # For [[var]]

  # File naming conventions
  naming:
    # Pattern for prompt files: {role}-{name}.st
    # role: system, user, assistant, etc.
    # name: evaluator, optimizer, etc.
    pattern: "{role}-{name}.st"

    # Recognized roles
    roles: ["system", "user"]

    # Var file pattern: {name}.yaml
    var_pattern: "{name}.yaml"

  # Auto-matching behavior
  matching:
    auto_match: true               # Auto-match prompts to vars by name
    allow_override: true           # Allow manual override in var files
    warn_orphans: true            # Warn about prompts without vars

# Git integration (minimal)
git:
  show_status: true          # Show git status in UI
  show_branch: true          # Show current branch
  show_uncommitted: true     # Show uncommitted changes count

# Default model settings for this workspace
defaults:
  provider: "openai"
  model: "gpt-4o"
  temperature: 0.7
  max_tokens: 2000

# Workspace settings
settings:
  auto_reload: true          # Watch for external file changes
  auto_extract_vars: true    # Auto-detect variables in prompts
  auto_save: false           # Auto-save on change (default: false)
```

---

## Variable Configuration Files

### Single Prompt (Simple Case)

```yaml
# evaluator.yaml
name: "Code Evaluator"
description: "Evaluates code quality and suggests improvements"

# Prompt files (auto-matched by name, or explicitly specified)
prompts:
  system: "system-evaluator.st"    # Explicit path (relative to prompt_dir)
  user: "user-evaluator.st"         # Explicit path

  # Alternative: rely on auto-matching
  # If omitted, will look for system-evaluator.st and user-evaluator.st

# Variables with test/dev values
variables:
  code_to_evaluate:
    type: file
    path: "../../examples/SampleService.java"
    description: "Sample Java code for testing"

  evaluation_criteria:
    type: value
    value: |
      - Code correctness and logic
      - Performance and efficiency
      - Security best practices
      - Code maintainability and readability
      - Error handling
    description: "Criteria for code evaluation"

  coding_standards:
    type: file
    path: "../../docs/java-coding-standards.md"
    description: "Company coding standards"

  max_issues:
    type: value
    value: "10"
    description: "Maximum number of issues to report"

# Model settings (override workspace defaults)
model:
  provider: "openai"
  name: "gpt-4o"
  temperature: 0.3      # Lower temp for consistent evaluation
  max_tokens: 3000

# Metadata
tags: ["evaluator", "code-review", "java"]
created: "2024-11-29"
last_modified: "2024-11-29"
```

### Auto-Matching Behavior

**Workspace has:**
- `system-evaluator.st`
- `user-evaluator.st`
- `evaluator.yaml`

**Auto-matching logic:**
1. Parse filename: `evaluator.yaml` â†’ name = "evaluator"
2. Look for prompts matching pattern: `{role}-evaluator.st`
3. Find: `system-evaluator.st` and `user-evaluator.st`
4. Map: system â†’ system-evaluator.st, user â†’ user-evaluator.st

**Manual override:**
```yaml
# evaluator.yaml
prompts:
  system: "custom-system-prompt.st"  # Override auto-match
  user: "user-evaluator.st"           # Use auto-matched
```

---

## Prompt Chaining

### Chain Configuration

```yaml
# evaluator-optimizer-chain.yaml
name: "Evaluator-Optimizer Chain"
description: "Evaluate code, optimize it, then re-evaluate"

# Shared context variables (available to all steps)
context:
  code_to_evaluate:
    type: file
    path: "../../examples/SampleService.java"

  coding_standards:
    type: file
    path: "../../docs/java-coding-standards.md"

# Chain steps (executed sequentially)
steps:
  - name: "evaluate"
    description: "Initial code evaluation"

    prompts:
      system: "system-evaluator.st"
      user: "user-evaluator.st"

    # Variables for this step (in addition to context)
    variables:
      evaluation_criteria:
        type: value
        value: "correctness, performance, security, maintainability"

      max_issues:
        type: value
        value: "10"

    # Model settings for this step
    model:
      provider: "openai"
      name: "gpt-4o"
      temperature: 0.3
      max_tokens: 3000

    # Output variable name (stores LLM response)
    output_var: "evaluation"

  - name: "optimize"
    description: "Optimize code based on evaluation"

    prompts:
      system: "system-optimizer.st"
      user: "user-optimizer.st"

    # Variables for this step
    variables:
      # Reference output from previous step
      evaluation: "{steps.evaluate.output}"

      optimization_focus:
        type: value
        value: "Address all critical and high-priority issues from evaluation"

    model:
      provider: "openai"
      name: "gpt-4o"
      temperature: 0.5
      max_tokens: 4000

    output_var: "optimized_code"

  - name: "validate"
    description: "Re-evaluate optimized code"

    prompts:
      system: "system-evaluator.st"
      user: "user-evaluator.st"

    variables:
      # Override context variable with optimized code
      code_to_evaluate: "{steps.optimize.output}"

      # Include previous evaluation for comparison
      previous_evaluation: "{steps.evaluate.output}"

      evaluation_criteria:
        type: value
        value: "Compare with previous evaluation, verify improvements"

    model:
      provider: "openai"
      name: "gpt-4o"
      temperature: 0.3
      max_tokens: 3000

    output_var: "final_evaluation"

    # Optional: conditional execution
    condition:
      run_if: "{steps.evaluate.needs_improvement}"  # Future: support conditionals

# Chain-level model defaults (used if step doesn't specify)
defaults:
  provider: "openai"
  model: "gpt-4o"
  temperature: 0.7
  max_tokens: 2000

# Metadata
tags: ["chain", "evaluator-optimizer", "code-improvement"]
created: "2024-11-29"
```

### Chain Execution Flow

```
Step 1: Evaluate
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Variables:                                      â”‚
â”‚   - code_to_evaluate: <SampleService.java content>     â”‚
â”‚   - coding_standards: <standards.md content>           â”‚
â”‚                                                         â”‚
â”‚ Step Variables:                                         â”‚
â”‚   - evaluation_criteria: "correctness, performance..." â”‚
â”‚   - max_issues: "10"                                   â”‚
â”‚                                                         â”‚
â”‚ Prompts:                                               â”‚
â”‚   - system-evaluator.st (interpolated)                 â”‚
â”‚   - user-evaluator.st (interpolated)                   â”‚
â”‚                                                         â”‚
â”‚ â†’ LLM Call â†’ evaluation output                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
Step 2: Optimize
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Variables:                                      â”‚
â”‚   - code_to_evaluate: <SampleService.java content>     â”‚
â”‚   - coding_standards: <standards.md content>           â”‚
â”‚                                                         â”‚
â”‚ Step Variables:                                         â”‚
â”‚   - evaluation: <output from step 1>                   â”‚
â”‚   - optimization_focus: "Address all critical..."      â”‚
â”‚                                                         â”‚
â”‚ Prompts:                                               â”‚
â”‚   - system-optimizer.st (interpolated)                 â”‚
â”‚   - user-optimizer.st (interpolated)                   â”‚
â”‚                                                         â”‚
â”‚ â†’ LLM Call â†’ optimized_code output                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
Step 3: Validate
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Variables (partially overridden):              â”‚
â”‚   - code_to_evaluate: <optimized_code from step 2>     â”‚
â”‚   - coding_standards: <standards.md content>           â”‚
â”‚                                                         â”‚
â”‚ Step Variables:                                         â”‚
â”‚   - previous_evaluation: <output from step 1>          â”‚
â”‚   - evaluation_criteria: "Compare with previous..."    â”‚
â”‚                                                         â”‚
â”‚ Prompts:                                               â”‚
â”‚   - system-evaluator.st (interpolated)                 â”‚
â”‚   - user-evaluator.st (interpolated)                   â”‚
â”‚                                                         â”‚
â”‚ â†’ LLM Call â†’ final_evaluation output                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Variable Interpolation Syntax

### Context Variables
```
{context.code_to_evaluate}
{context.coding_standards}
```

### Step Outputs
```
{steps.evaluate.output}           # Full output from 'evaluate' step
{steps.optimize.output}           # Full output from 'optimize' step
```

### Nested Access (Future)
```
{steps.evaluate.output.issues[0]}      # First issue from JSON response
{steps.evaluate.output.severity}       # Severity field
```

---

## Template Syntax Support

### Configurable Delimiters

The tool supports any delimiter configuration:

| Config | Example | Common Usage |
|--------|---------|--------------|
| `{` `}` | `{variable}` | Spring default, Python, Jinja2 |
| `$` `$` | `$variable$` | StringTemplate alternate |
| `<` `>` | `<variable>` | StringTemplate alternate |
| `[[` `]]` | `[[variable]]` | MediaWiki style |
| `${` `}` | `${variable}` | Shell, Spring EL |

**Variable Extraction:**
```python
def extract_variables(template: str, start: str, end: str) -> List[str]:
    """
    Extract variable names from template with custom delimiters.

    Example:
      template = "Hello {name}, your code: {code}"
      start = "{"
      end = "}"
      â†’ ["name", "code"]
    """
    # Escape special regex chars
    start_escaped = re.escape(start)
    end_escaped = re.escape(end)

    # Pattern: {start}word_chars{end}
    pattern = f'{start_escaped}(\\w+){end_escaped}'
    return re.findall(pattern, template)
```

**Variable Substitution:**
```python
def render_template(template: str, variables: Dict, start: str, end: str) -> str:
    """
    Render template with variables using custom delimiters.

    Example:
      template = "Hello {name}"
      variables = {"name": "Alice"}
      start = "{"
      end = "}"
      â†’ "Hello Alice"
    """
    result = template
    for key, value in variables.items():
        placeholder = f"{start}{key}{end}"
        result = result.replace(placeholder, str(value))
    return result
```

---

## File Discovery & Matching

### Discovery Process

1. **Scan prompt_dir:**
   ```
   src/main/resources/prompts/
   â”œâ”€â”€ system-evaluator.st
   â”œâ”€â”€ user-evaluator.st
   â”œâ”€â”€ system-optimizer.st
   â”œâ”€â”€ user-optimizer.st
   â””â”€â”€ legacy-prompt.st
   ```

2. **Scan vars_dir:**
   ```
   src/test/resources/prompts/vars/
   â”œâ”€â”€ evaluator.yaml
   â”œâ”€â”€ optimizer.yaml
   â””â”€â”€ evaluator-optimizer-chain.yaml
   ```

3. **Auto-match prompts to vars:**
   - `evaluator.yaml` â†’ `system-evaluator.st` + `user-evaluator.st`
   - `optimizer.yaml` â†’ `system-optimizer.st` + `user-optimizer.st`
   - `legacy-prompt.st` â†’ âš ï¸ orphan (no matching var file)

4. **Display in UI:**
   ```
   Prompts/
   â”œâ”€â”€ evaluator (system, user)
   â”œâ”€â”€ optimizer (system, user)
   â””â”€â”€ âš ï¸ legacy-prompt (orphan)

   Chains/
   â””â”€â”€ evaluator-optimizer-chain
   ```

### Matching Rules

**Naming convention:** `{role}-{name}.{ext}`

| Prompt File | Extracted Name | Matched Var File |
|-------------|----------------|------------------|
| `system-evaluator.st` | `evaluator` | `evaluator.yaml` |
| `user-evaluator.st` | `evaluator` | `evaluator.yaml` |
| `system-optimizer.st` | `optimizer` | `optimizer.yaml` |
| `legacy-prompt.st` | N/A (no role prefix) | âš ï¸ orphan |

**Override in var file:**
```yaml
# evaluator.yaml
prompts:
  system: "custom-system.st"      # Override auto-match
  user: "user-evaluator.st"       # Use auto-match (or explicit)
```

---

## UI Layout

### Left Navigation Panel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ Workspace: MyApp          â”‚
â”‚    Branch: main [â—2]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ” Search prompts...         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ Prompts                   â”‚
â”‚   â–¸ evaluator               â”‚
â”‚   â–¸ optimizer               â”‚
â”‚   âš ï¸ legacy-prompt (orphan) â”‚
â”‚                              â”‚
â”‚ ğŸ”— Chains                    â”‚
â”‚   â–¸ evaluator-optimizer     â”‚
â”‚                              â”‚
â”‚ ğŸ“Š History                   â”‚
â”‚   â–¸ Recent runs (5)         â”‚
â”‚                              â”‚
â”‚ ğŸ”§ Settings                  â”‚
â”‚   â€¢ Workspace config        â”‚
â”‚   â€¢ Providers               â”‚
â”‚   â€¢ Git status              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Main Workspace

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Provider: OpenAI â–¼] [Model: gpt-4o â–¼] [Temp: 0.7] [âš™ï¸ â–¼]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Prompt: evaluator                                    [Save] [â–¶ï¸ Run]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ System Prompt  [system-evaluator.st]              [Edit ğŸ“]â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚ â”‚ You are an expert code reviewer...                         â”‚ â”‚
â”‚ â”‚ (collapsed - click to expand)                              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ User Prompt  [user-evaluator.st]                  [Edit ğŸ“]â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚ â”‚ Please evaluate the following code:                        â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ ```java                                                     â”‚ â”‚
â”‚ â”‚ {code_to_evaluate}                                         â”‚ â”‚
â”‚ â”‚ ```                                                         â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ Evaluation criteria: {evaluation_criteria}                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚ Variables  [evaluator.yaml]                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ code_to_evaluate         [ğŸ“„ File]                          â”‚ â”‚
â”‚ â”‚   ../../examples/SampleService.java                        â”‚ â”‚
â”‚ â”‚   [Browse...] [Preview â–¼]                                  â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ evaluation_criteria      [ğŸ“ Value]                         â”‚ â”‚
â”‚ â”‚   - Code correctness and logic                             â”‚ â”‚
â”‚ â”‚   - Performance and efficiency                             â”‚ â”‚
â”‚ â”‚   - Security best practices                                â”‚ â”‚
â”‚ â”‚   [Edit...]                                                â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ coding_standards         [ğŸ“„ File]                          â”‚ â”‚
â”‚ â”‚   ../../docs/java-coding-standards.md                      â”‚ â”‚
â”‚ â”‚   [Browse...] [Preview â–¼]                                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Tabs: [Formatted] [Raw Request] [Raw Response]             â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚ â”‚ Response appears here...                                   â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ [Copy] [Save to File]                                      â”‚ â”‚
â”‚ â”‚                                                             â”‚ â”‚
â”‚ â”‚ Tokens: 1,234 | Cost: $0.05 | Time: 2.3s                  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Maven/Gradle Awareness (Nice-to-Have)

### Auto-Detection

When opening a workspace, detect project structure:

```python
def detect_project_type(path: Path) -> Optional[str]:
    """Detect project type from directory structure."""
    if (path / "pom.xml").exists():
        return "maven"
    elif (path / "build.gradle").exists() or (path / "build.gradle.kts").exists():
        return "gradle"
    elif (path / "package.json").exists():
        return "nodejs"
    elif (path / "requirements.txt").exists() or (path / "pyproject.toml").exists():
        return "python"
    return None
```

### Auto-Suggest Layout

```
Detected: Maven project
Suggested layout:
  prompt_dir: src/main/resources/prompts
  vars_dir: src/test/resources/prompts/vars

[Accept] [Customize]
```

---

## Implementation Notes

### Phase 1 Priorities

1. **Workspace management** - Critical foundation
2. **Configurable delimiters** - Support Spring's flexibility
3. **File auto-matching** - Low-friction UX
4. **Basic variable UI** - Core iteration workflow

### Phase 2 Priorities

1. **Chain builder** - Evaluator-optimizer pattern
2. **Chain execution engine** - Sequential step processing
3. **Chain debugging UI** - See intermediate results

### Phase 3 Priorities

1. **Maven/Gradle detection** - Nice-to-have
2. **Advanced chain features** - Conditionals, loops
3. **Visual workflow builder** - Drag-drop chains

---

## Open Questions

1. **Delimiter escaping**: How to handle literal `{` or `}` in prompts when using those as delimiters?
   - Suggestion: `\{` and `\}` for escaping

2. **Chain state persistence**: Should chain execution state be saved between runs?
   - Suggestion: Save to `chain_runs/` directory with timestamp

3. **Multi-role prompts**: What if you need more than system/user?
   - Suggestion: Support arbitrary roles: `assistant-evaluator.st`, `context-evaluator.st`

4. **Variable validation**: Should the tool validate variables before running?
   - Check file paths exist
   - Check required variables are defined
   - Type checking (future)?

---

**Last Updated**: 2024-11-29
